{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 977,
   "id": "00a74534",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "import nltk\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "from scipy.sparse import hstack\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import accuracy_score,recall_score,f1_score,precision_score"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7244942",
   "metadata": {},
   "source": [
    "## Reading the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 978,
   "id": "14474f13",
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_data(filename):\n",
    "    data = pd.read_csv(filename,sep='\\t',on_bad_lines='skip',header=None)\n",
    "    data = data.loc[~data[1].isin(['teating', 'training  Langdon','testing Camilla','training  Selander  ████████ keeps the action moving ahead at a full gallop.'])]\n",
    "    df = data.rename(columns = {0 : \"github_username\",1: \"file_type\",2 : \"entity_name\",3:\"redaction_context\"},inplace = False)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 979,
   "id": "05fac86f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = read_data('unredactor.tsv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 980,
   "id": "e6b09714",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>github_username</th>\n",
       "      <th>file_type</th>\n",
       "      <th>entity_name</th>\n",
       "      <th>redaction_context</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>cegme</td>\n",
       "      <td>training</td>\n",
       "      <td>ashton kutcher</td>\n",
       "      <td>I couldn't image ██████████████ in a serious r...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>SarahBrown</td>\n",
       "      <td>training</td>\n",
       "      <td>Ashton Kutcher</td>\n",
       "      <td>I'll admit that I was reluctant to see it beca...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>SarahBrown</td>\n",
       "      <td>training</td>\n",
       "      <td>Noonan</td>\n",
       "      <td>The acting is all up to ██████ and he carries ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>SarahBrown</td>\n",
       "      <td>training</td>\n",
       "      <td>Picasso</td>\n",
       "      <td>███████ was a finer draftsman and a brilliant ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>SarahBrown</td>\n",
       "      <td>training</td>\n",
       "      <td>Tom Noonan</td>\n",
       "      <td>The incredible performance by ██████████ is br...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2913</th>\n",
       "      <td>pinn0002</td>\n",
       "      <td>testing</td>\n",
       "      <td>Miike</td>\n",
       "      <td>And it all leads up to one last, inexplicable ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2914</th>\n",
       "      <td>pinn0002</td>\n",
       "      <td>testing</td>\n",
       "      <td>Diane</td>\n",
       "      <td>They also represent her feelings of guilt from...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2915</th>\n",
       "      <td>pinn0002</td>\n",
       "      <td>testing</td>\n",
       "      <td>Ron Howard</td>\n",
       "      <td>Sadly, that's what this ██████████ film did, w...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2917</th>\n",
       "      <td>pinn0002</td>\n",
       "      <td>testing</td>\n",
       "      <td>Adam</td>\n",
       "      <td>She's mainly a strong authority figure, as can...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2918</th>\n",
       "      <td>pinn0002</td>\n",
       "      <td>testing</td>\n",
       "      <td>David Lynch</td>\n",
       "      <td>If you have the DVD of MD, you can \"cheat\" by ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2915 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     github_username file_type     entity_name  \\\n",
       "0              cegme  training  ashton kutcher   \n",
       "1         SarahBrown  training  Ashton Kutcher   \n",
       "2         SarahBrown  training          Noonan   \n",
       "3         SarahBrown  training         Picasso   \n",
       "4         SarahBrown  training      Tom Noonan   \n",
       "...              ...       ...             ...   \n",
       "2913        pinn0002   testing           Miike   \n",
       "2914        pinn0002   testing           Diane   \n",
       "2915        pinn0002   testing      Ron Howard   \n",
       "2917        pinn0002   testing            Adam   \n",
       "2918        pinn0002   testing     David Lynch   \n",
       "\n",
       "                                      redaction_context  \n",
       "0     I couldn't image ██████████████ in a serious r...  \n",
       "1     I'll admit that I was reluctant to see it beca...  \n",
       "2     The acting is all up to ██████ and he carries ...  \n",
       "3     ███████ was a finer draftsman and a brilliant ...  \n",
       "4     The incredible performance by ██████████ is br...  \n",
       "...                                                 ...  \n",
       "2913  And it all leads up to one last, inexplicable ...  \n",
       "2914  They also represent her feelings of guilt from...  \n",
       "2915  Sadly, that's what this ██████████ film did, w...  \n",
       "2917  She's mainly a strong authority figure, as can...  \n",
       "2918  If you have the DVD of MD, you can \"cheat\" by ...  \n",
       "\n",
       "[2915 rows x 4 columns]"
      ]
     },
     "execution_count": 980,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd0be242",
   "metadata": {},
   "source": [
    "## Processing Redacted text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 981,
   "id": "6a4296f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocessed(data):\n",
    "    preprocessed = []\n",
    "    for text in data.values:\n",
    "        text=re.sub(r'n\\'t',' not',str(text))\n",
    "        text=re.sub(r\"can't\",\"can not\",text)\n",
    "        text=re.sub(\"n\\'t\",\"not\",text)\n",
    "        text=re.sub(\"\\'re\",\"are\",text)\n",
    "        text=re.sub(\"\\'s\",\" \",text)\n",
    "        text=re.sub(\"\\'d\",\" would\",text)\n",
    "        text=re.sub(\"\\'ll\",\" will\",text)    \n",
    "        text=re.sub(\"\\'t\",\" not\",text)\n",
    "        text=re.sub(\"\\'ve\",\" have\",text)\n",
    "        text=re.sub(\"\\'m\",\" am\",text)\n",
    "        text = text.replace('<br>','')\n",
    "        text = text.replace('</br>','')\n",
    "        text = text.replace('-',' ')\n",
    "        text = re.sub('[?|!|\\'|\"|#]',r'',text)\n",
    "        text = re.sub('[.|,|)|(|\\|/]',r'',text)\n",
    "        text = ' '.join(e for e in text.split())    \n",
    "        preprocessed.append(text)\n",
    "    return preprocessed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 982,
   "id": "b3342f6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "processed_data = preprocessed(df['redaction_context'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 983,
   "id": "01d6b969",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['preprocessed_redeacted_context'] = processed_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 984,
   "id": "037be32f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>github_username</th>\n",
       "      <th>file_type</th>\n",
       "      <th>entity_name</th>\n",
       "      <th>redaction_context</th>\n",
       "      <th>preprocessed_redeacted_context</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>cegme</td>\n",
       "      <td>training</td>\n",
       "      <td>ashton kutcher</td>\n",
       "      <td>I couldn't image ██████████████ in a serious r...</td>\n",
       "      <td>I could not image ██████████████ in a serious ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>SarahBrown</td>\n",
       "      <td>training</td>\n",
       "      <td>Ashton Kutcher</td>\n",
       "      <td>I'll admit that I was reluctant to see it beca...</td>\n",
       "      <td>I will admit that I was reluctant to see it be...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>SarahBrown</td>\n",
       "      <td>training</td>\n",
       "      <td>Noonan</td>\n",
       "      <td>The acting is all up to ██████ and he carries ...</td>\n",
       "      <td>The acting is all up to ██████ and he carries ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>SarahBrown</td>\n",
       "      <td>training</td>\n",
       "      <td>Picasso</td>\n",
       "      <td>███████ was a finer draftsman and a brilliant ...</td>\n",
       "      <td>███████ was a finer draftsman and a brilliant ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>SarahBrown</td>\n",
       "      <td>training</td>\n",
       "      <td>Tom Noonan</td>\n",
       "      <td>The incredible performance by ██████████ is br...</td>\n",
       "      <td>The incredible performance by ██████████ is br...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2913</th>\n",
       "      <td>pinn0002</td>\n",
       "      <td>testing</td>\n",
       "      <td>Miike</td>\n",
       "      <td>And it all leads up to one last, inexplicable ...</td>\n",
       "      <td>And it all leads up to one last inexplicable s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2914</th>\n",
       "      <td>pinn0002</td>\n",
       "      <td>testing</td>\n",
       "      <td>Diane</td>\n",
       "      <td>They also represent her feelings of guilt from...</td>\n",
       "      <td>They also represent her feelings of guilt from...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2915</th>\n",
       "      <td>pinn0002</td>\n",
       "      <td>testing</td>\n",
       "      <td>Ron Howard</td>\n",
       "      <td>Sadly, that's what this ██████████ film did, w...</td>\n",
       "      <td>Sadly that what this ██████████ film did with ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2917</th>\n",
       "      <td>pinn0002</td>\n",
       "      <td>testing</td>\n",
       "      <td>Adam</td>\n",
       "      <td>She's mainly a strong authority figure, as can...</td>\n",
       "      <td>She mainly a strong authority figure as can be...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2918</th>\n",
       "      <td>pinn0002</td>\n",
       "      <td>testing</td>\n",
       "      <td>David Lynch</td>\n",
       "      <td>If you have the DVD of MD, you can \"cheat\" by ...</td>\n",
       "      <td>If you have the DVD of MD you can cheat by loo...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2915 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     github_username file_type     entity_name  \\\n",
       "0              cegme  training  ashton kutcher   \n",
       "1         SarahBrown  training  Ashton Kutcher   \n",
       "2         SarahBrown  training          Noonan   \n",
       "3         SarahBrown  training         Picasso   \n",
       "4         SarahBrown  training      Tom Noonan   \n",
       "...              ...       ...             ...   \n",
       "2913        pinn0002   testing           Miike   \n",
       "2914        pinn0002   testing           Diane   \n",
       "2915        pinn0002   testing      Ron Howard   \n",
       "2917        pinn0002   testing            Adam   \n",
       "2918        pinn0002   testing     David Lynch   \n",
       "\n",
       "                                      redaction_context  \\\n",
       "0     I couldn't image ██████████████ in a serious r...   \n",
       "1     I'll admit that I was reluctant to see it beca...   \n",
       "2     The acting is all up to ██████ and he carries ...   \n",
       "3     ███████ was a finer draftsman and a brilliant ...   \n",
       "4     The incredible performance by ██████████ is br...   \n",
       "...                                                 ...   \n",
       "2913  And it all leads up to one last, inexplicable ...   \n",
       "2914  They also represent her feelings of guilt from...   \n",
       "2915  Sadly, that's what this ██████████ film did, w...   \n",
       "2917  She's mainly a strong authority figure, as can...   \n",
       "2918  If you have the DVD of MD, you can \"cheat\" by ...   \n",
       "\n",
       "                         preprocessed_redeacted_context  \n",
       "0     I could not image ██████████████ in a serious ...  \n",
       "1     I will admit that I was reluctant to see it be...  \n",
       "2     The acting is all up to ██████ and he carries ...  \n",
       "3     ███████ was a finer draftsman and a brilliant ...  \n",
       "4     The incredible performance by ██████████ is br...  \n",
       "...                                                 ...  \n",
       "2913  And it all leads up to one last inexplicable s...  \n",
       "2914  They also represent her feelings of guilt from...  \n",
       "2915  Sadly that what this ██████████ film did with ...  \n",
       "2917  She mainly a strong authority figure as can be...  \n",
       "2918  If you have the DVD of MD you can cheat by loo...  \n",
       "\n",
       "[2915 rows x 5 columns]"
      ]
     },
     "execution_count": 984,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "851a6f4a",
   "metadata": {},
   "source": [
    "## Processing of Entity Name column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 985,
   "id": "d8057d61",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocessed_label(data):\n",
    "    label = []\n",
    "    for text in data.values: \n",
    "        text=re.sub(\"\\'s\",\" \",str(text))\n",
    "        text=text.replace('.','')\n",
    "        label.append(text)\n",
    "    return label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 986,
   "id": "69169690",
   "metadata": {},
   "outputs": [],
   "source": [
    "label_in = preprocessed_label(df['entity_name'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 987,
   "id": "08d69f2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['entity_name_label'] = label_in"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60293ccc",
   "metadata": {},
   "source": [
    "## Extract number of letter in redacted words and adding as a feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 988,
   "id": "9b9e4762",
   "metadata": {},
   "outputs": [],
   "source": [
    "def number_of_letter(data):\n",
    "    count_letter = []\n",
    "    for i in data.values:\n",
    "        a = len(list(filter(str.isalpha, i)))\n",
    "        count_letter.append(a)\n",
    "    return count_letter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 989,
   "id": "3ca5a8a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "c =number_of_letter(df['entity_name_label'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 990,
   "id": "b595e053",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['count_of_letter_of_redeacted words'] = c"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aaeb202d",
   "metadata": {},
   "source": [
    "## Extract number of spaces in redacted words and adding as another feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 991,
   "id": "f62b3eb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def number_of_spaces(data):\n",
    "    count = 0\n",
    "    for i in data:\n",
    "        for j in i:\n",
    "            if(i.isspace()):\n",
    "                count=count+1\n",
    "    return count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 992,
   "id": "ac3f29ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['count_number of_spaces'] = df['entity_name_label'].apply(lambda c:number_of_spaces(c))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aba42790",
   "metadata": {},
   "source": [
    "## Dropping redundant columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 993,
   "id": "b2950484",
   "metadata": {},
   "outputs": [],
   "source": [
    "def drop_unnecessary_columns(data):\n",
    "    data = data.drop(['entity_name','github_username','redaction_context'],axis=1, inplace=False)\n",
    "    return data    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 994,
   "id": "29f9e54b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = drop_unnecessary_columns(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 995,
   "id": "21729d90",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>file_type</th>\n",
       "      <th>preprocessed_redeacted_context</th>\n",
       "      <th>entity_name_label</th>\n",
       "      <th>count_of_letter_of_redeacted words</th>\n",
       "      <th>count_number of_spaces</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>training</td>\n",
       "      <td>I could not image ██████████████ in a serious ...</td>\n",
       "      <td>ashton kutcher</td>\n",
       "      <td>13</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>training</td>\n",
       "      <td>I will admit that I was reluctant to see it be...</td>\n",
       "      <td>Ashton Kutcher</td>\n",
       "      <td>13</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>training</td>\n",
       "      <td>The acting is all up to ██████ and he carries ...</td>\n",
       "      <td>Noonan</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>training</td>\n",
       "      <td>███████ was a finer draftsman and a brilliant ...</td>\n",
       "      <td>Picasso</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>training</td>\n",
       "      <td>The incredible performance by ██████████ is br...</td>\n",
       "      <td>Tom Noonan</td>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2913</th>\n",
       "      <td>testing</td>\n",
       "      <td>And it all leads up to one last inexplicable s...</td>\n",
       "      <td>Miike</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2914</th>\n",
       "      <td>testing</td>\n",
       "      <td>They also represent her feelings of guilt from...</td>\n",
       "      <td>Diane</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2915</th>\n",
       "      <td>testing</td>\n",
       "      <td>Sadly that what this ██████████ film did with ...</td>\n",
       "      <td>Ron Howard</td>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2917</th>\n",
       "      <td>testing</td>\n",
       "      <td>She mainly a strong authority figure as can be...</td>\n",
       "      <td>Adam</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2918</th>\n",
       "      <td>testing</td>\n",
       "      <td>If you have the DVD of MD you can cheat by loo...</td>\n",
       "      <td>David Lynch</td>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2915 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     file_type                     preprocessed_redeacted_context  \\\n",
       "0     training  I could not image ██████████████ in a serious ...   \n",
       "1     training  I will admit that I was reluctant to see it be...   \n",
       "2     training  The acting is all up to ██████ and he carries ...   \n",
       "3     training  ███████ was a finer draftsman and a brilliant ...   \n",
       "4     training  The incredible performance by ██████████ is br...   \n",
       "...        ...                                                ...   \n",
       "2913   testing  And it all leads up to one last inexplicable s...   \n",
       "2914   testing  They also represent her feelings of guilt from...   \n",
       "2915   testing  Sadly that what this ██████████ film did with ...   \n",
       "2917   testing  She mainly a strong authority figure as can be...   \n",
       "2918   testing  If you have the DVD of MD you can cheat by loo...   \n",
       "\n",
       "     entity_name_label  count_of_letter_of_redeacted words  \\\n",
       "0       ashton kutcher                                  13   \n",
       "1       Ashton Kutcher                                  13   \n",
       "2               Noonan                                   6   \n",
       "3              Picasso                                   7   \n",
       "4           Tom Noonan                                   9   \n",
       "...                ...                                 ...   \n",
       "2913             Miike                                   5   \n",
       "2914             Diane                                   5   \n",
       "2915        Ron Howard                                   9   \n",
       "2917              Adam                                   4   \n",
       "2918       David Lynch                                  10   \n",
       "\n",
       "      count_number of_spaces  \n",
       "0                          1  \n",
       "1                          1  \n",
       "2                          0  \n",
       "3                          0  \n",
       "4                          1  \n",
       "...                      ...  \n",
       "2913                       0  \n",
       "2914                       0  \n",
       "2915                       1  \n",
       "2917                       0  \n",
       "2918                       1  \n",
       "\n",
       "[2915 rows x 5 columns]"
      ]
     },
     "execution_count": 995,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b43663e1",
   "metadata": {},
   "source": [
    "## Splitting into train and test and also create a copy of the test data for displaying the output later"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 996,
   "id": "fefcc345",
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_into_train_val_test(data):\n",
    "    X_train=data[data['file_type']=='training'].drop(['entity_name_label'],axis=1)\n",
    "    y_train=data[data['file_type']=='training']['entity_name_label']\n",
    "    X_val=data[data['file_type']=='validation'].drop(['entity_name_label'],axis=1)\n",
    "    y_val=data[data['file_type']=='validation']['entity_name_label']\n",
    "    X_test=data[data['file_type']=='testing'].drop(['entity_name_label'],axis=1)\n",
    "    y_test=data[data['file_type']=='testing']['entity_name_label']\n",
    "    X_test_out = X_test.copy()\n",
    "    return (X_train,y_train,X_val,y_val,X_test,y_test,X_test_out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 997,
   "id": "c341aefe",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train,y_train,X_val,y_val,X_test,y_test,X_test_out=split_into_train_val_test(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 998,
   "id": "8b9a5c5e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1612,)"
      ]
     },
     "execution_count": 998,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b1433f2",
   "metadata": {},
   "source": [
    "## Featurization with n-gram for train,validation and test dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 999,
   "id": "775fd2b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_featurization_n_gram(data1,data2,data3):\n",
    "    vect = CountVectorizer()\n",
    "    vect.fit(data1.values)\n",
    "    X_train_redeacted_context = vect.transform(data1.values)\n",
    "    X_val_redeacted_context = vect.transform(data2.values)\n",
    "    X_test_redeacted_context = vect.transform(data3.values)\n",
    "    return (X_train_redeacted_context,X_val_redeacted_context,X_test_redeacted_context)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1000,
   "id": "89dcc77a",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_redeacted_context,X_val_redeacted_context, X_test_redeacted_context= get_featurization_n_gram(X_train['preprocessed_redeacted_context'],X_val['preprocessed_redeacted_context'],X_test['preprocessed_redeacted_context'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1e16569",
   "metadata": {},
   "source": [
    "## Featurization with total number letters in redacted words for train,validation and test dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1001,
   "id": "4282e4c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_featurization_count_letter(data1,data2,data3):\n",
    "    X_train_count_of_letter_of_redeacted = data1.values.reshape(-1,1)\n",
    "    X_val_count_of_letter_of_redeacted= data2.values.reshape(-1,1)\n",
    "    X_test_count_of_letter_of_redeacted= data3.values.reshape(-1,1)\n",
    "    return (X_train_count_of_letter_of_redeacted,X_val_count_of_letter_of_redeacted,X_test_count_of_letter_of_redeacted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1002,
   "id": "929e908a",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_count_of_letter_of_redeacted,X_val_count_of_letter_of_redeacted,X_test_count_of_letter_of_redeacted = get_featurization_count_letter(X_train['count_of_letter_of_redeacted words'],X_val['count_of_letter_of_redeacted words'],X_test['count_of_letter_of_redeacted words'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b536d8d6",
   "metadata": {},
   "source": [
    "## Featurization with total number of spaces in redacted words for train,validation and test dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1003,
   "id": "be046b6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_featurization_count_spaces(data1,data2,data3):\n",
    "    X_train_count_number_of_spaces = data1.values.reshape(-1,1)\n",
    "    X_val_count_number_of_spaces= data2.values.reshape(-1,1)\n",
    "    X_test_count_number_of_spaces= data3.values.reshape(-1,1)\n",
    "    return (X_train_count_number_of_spaces,X_val_count_number_of_spaces,X_test_count_number_of_spaces)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1004,
   "id": "51e96c22",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_count_number_of_spaces,X_val_count_number_of_spaces,X_test_count_number_of_spaces =  get_featurization_count_spaces(X_train['count_number of_spaces'],X_val['count_number of_spaces'],X_test['count_number of_spaces'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1005,
   "id": "ea0d601f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def merge_features(data1,data2,data3):\n",
    "    data  = hstack((data1,data2,data3)).tocsr()\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1006,
   "id": "ba28ef6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_tr = merge_features(X_train_redeacted_context,X_train_count_of_letter_of_redeacted,X_train_count_number_of_spaces)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1007,
   "id": "829ae63f",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_cv = merge_features(X_val_redeacted_context,X_val_count_of_letter_of_redeacted,X_val_count_number_of_spaces)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1008,
   "id": "74df9eb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_te = merge_features(X_test_redeacted_context,X_test_count_of_letter_of_redeacted,X_test_count_number_of_spaces)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14bc746d",
   "metadata": {},
   "source": [
    "## Model Prediction and Evaluation of model using Precision, Recall and F1-score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1009,
   "id": "41724d8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_evaluation(data1,data2,data3,y_train):\n",
    "    clf = DecisionTreeClassifier(random_state=0)\n",
    "    model = clf.fit(data1,y_train)\n",
    "    y_train_predicted=model.predict(data1)\n",
    "    y_val_predicted=model.predict(data2)\n",
    "    y_test_predicted=model.predict(data3)\n",
    "    train_precision_score=precision_score(y_train, y_train_predicted,average='weighted')\n",
    "    val_precision_score=precision_score(y_val, y_val_predicted,average='weighted')\n",
    "    train_recall_score=recall_score(y_train, y_train_predicted,average='weighted')\n",
    "    val_recall_score=recall_score(y_val, y_val_predicted,average='weighted')\n",
    "    train_f1_score=f1_score(y_train, y_train_predicted,average='weighted')\n",
    "    val_f1_score=f1_score(y_val, y_val_predicted,average='weighted')\n",
    "    return (y_test_predicted,train_precision_score,val_precision_score,train_recall_score,val_recall_score,train_f1_score,val_f1_score)   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1010,
   "id": "810a2517",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test_predicted,train_precision_score,val_precision_score,train_recall_score,val_recall_score,train_f1_score,val_f1_score= model_evaluation(X_tr,X_cv,X_te,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1011,
   "id": "66a859e1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(336,)"
      ]
     },
     "execution_count": 1011,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test_predicted.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cbc950be",
   "metadata": {},
   "source": [
    "## Creating a column in the test dataset and displaying unredacted text(after prediction) in that column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1012,
   "id": "7034d998",
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_output(data,y_pred):\n",
    "    data['unredeacted'] = y_pred\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1013,
   "id": "d136b379",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>file_type</th>\n",
       "      <th>preprocessed_redeacted_context</th>\n",
       "      <th>count_of_letter_of_redeacted words</th>\n",
       "      <th>count_number of_spaces</th>\n",
       "      <th>unredeacted</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>81</th>\n",
       "      <td>testing</td>\n",
       "      <td>The mentor this time is played perfectly by ██...</td>\n",
       "      <td>12</td>\n",
       "      <td>1</td>\n",
       "      <td>Dianne Keaton</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>82</th>\n",
       "      <td>testing</td>\n",
       "      <td>While his scenes with the local love interest ...</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>Brosnan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>83</th>\n",
       "      <td>testing</td>\n",
       "      <td>Well I have to disagree with ██████████████ on...</td>\n",
       "      <td>13</td>\n",
       "      <td>1</td>\n",
       "      <td>Danielle Petty</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>84</th>\n",
       "      <td>testing</td>\n",
       "      <td>Director ████████████ offers endless laughters...</td>\n",
       "      <td>11</td>\n",
       "      <td>1</td>\n",
       "      <td>Sean Connery</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>85</th>\n",
       "      <td>testing</td>\n",
       "      <td>It will be the death of ███████████████ Fascin...</td>\n",
       "      <td>13</td>\n",
       "      <td>2</td>\n",
       "      <td>Vince Guaraldi</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2913</th>\n",
       "      <td>testing</td>\n",
       "      <td>And it all leads up to one last inexplicable s...</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>Rocky</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2914</th>\n",
       "      <td>testing</td>\n",
       "      <td>They also represent her feelings of guilt from...</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>Julia</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2915</th>\n",
       "      <td>testing</td>\n",
       "      <td>Sadly that what this ██████████ film did with ...</td>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "      <td>Wes Craven</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2917</th>\n",
       "      <td>testing</td>\n",
       "      <td>She mainly a strong authority figure as can be...</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>Raul</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2918</th>\n",
       "      <td>testing</td>\n",
       "      <td>If you have the DVD of MD you can cheat by loo...</td>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "      <td>Dutch Henry</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>336 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     file_type                     preprocessed_redeacted_context  \\\n",
       "81     testing  The mentor this time is played perfectly by ██...   \n",
       "82     testing  While his scenes with the local love interest ...   \n",
       "83     testing  Well I have to disagree with ██████████████ on...   \n",
       "84     testing  Director ████████████ offers endless laughters...   \n",
       "85     testing  It will be the death of ███████████████ Fascin...   \n",
       "...        ...                                                ...   \n",
       "2913   testing  And it all leads up to one last inexplicable s...   \n",
       "2914   testing  They also represent her feelings of guilt from...   \n",
       "2915   testing  Sadly that what this ██████████ film did with ...   \n",
       "2917   testing  She mainly a strong authority figure as can be...   \n",
       "2918   testing  If you have the DVD of MD you can cheat by loo...   \n",
       "\n",
       "      count_of_letter_of_redeacted words  count_number of_spaces  \\\n",
       "81                                    12                       1   \n",
       "82                                     7                       0   \n",
       "83                                    13                       1   \n",
       "84                                    11                       1   \n",
       "85                                    13                       2   \n",
       "...                                  ...                     ...   \n",
       "2913                                   5                       0   \n",
       "2914                                   5                       0   \n",
       "2915                                   9                       1   \n",
       "2917                                   4                       0   \n",
       "2918                                  10                       1   \n",
       "\n",
       "          unredeacted  \n",
       "81      Dianne Keaton  \n",
       "82            Brosnan  \n",
       "83     Danielle Petty  \n",
       "84       Sean Connery  \n",
       "85    Vince Guaraldi   \n",
       "...               ...  \n",
       "2913            Rocky  \n",
       "2914            Julia  \n",
       "2915       Wes Craven  \n",
       "2917             Raul  \n",
       "2918      Dutch Henry  \n",
       "\n",
       "[336 rows x 5 columns]"
      ]
     },
     "execution_count": 1013,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "show_output(X_test_out,y_test_predicted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a28e3078",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21a33a1e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
